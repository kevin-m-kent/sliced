update(mtry = mtry(c(1, 20)), sample_size = sample_size(c(1, 500)))
wfset <- workflow_set(
preproc = list(xgb_recp = xbg_recip),
models = list(xgb_mod = xgb),
cross = FALSE
)
wfset <-
wfset %>%
option_add(param = xgb_param, id = "xgb_recp_xgb_mod")
grid_ctrl <-
control_grid(
save_pred = TRUE,
parallel_over = "everything",
save_workflow = TRUE
)
grid_results <-
wfset %>%
workflow_map(
seed = 1503,
resamples = folds,
grid = 15,
control = grid_ctrl,
metrics = metrics
)
grid_results$result[[1]]
?min_n
min_n()
tree_dept()
tree_depth
wfset
xgb_param <-
xgb %>%
parameters() %>%
update(mtry = mtry(c(1, 20)), sample_size = sample_size(c(1, 500)))
wfset <- workflow_set(
preproc = list(xgb_recp = xbg_recip),
models = list(xgb_mod = xgb),
cross = FALSE
)
wfset <-
wfset %>%
option_add(param = xgb_param, id = "xgb_recp_xgb_mod")
wkflow <- workflow() %>%
add_recipe(xbg_recip) %>%
add_model(xgb)
final_wkflow <- wkflow %>%
finalize_workflow(xgb_param)
min_n()
wkflow <- workflow() %>%
add_recipe(xbg_recip) %>%
add_model(xgb)
?tune_grid
tuned_results <- wkflow %>%
tune_grid(
folds,
grid = 15,
param_info = xgb_param
)
tuned_results$.notes[[1]]
tuned_results$.notes[[1]][[1]]
xbg_recip <- recipe(price ~ ., data = train) %>%
step_tokenize(name) %>%
step_stopwords(name) %>%
step_tokenfilter(name) %>%
step_tf(name) %>%
step_dummy(neighbourhood, neighbourhood_group) %>%
step_mutate(date_since_today = as.numeric(Sys.Date() - last_review)) %>%
step_mutate(distance_ctr = sqrt((tssq_lat - latitude)^2 + (tssq_lon - longitude)^2)) %>%
step_rm(all_nominal_predictors())
linear_reg <- linear_reg() %>%
set_engine("lm")
xgb <- boost_tree(mtry = tune(),
trees = 1000,
min_n = tune(),
tree_depth = tune(),
learn_rate = tune(),
sample_size = tune()) %>%
set_engine("xgboost") %>%
set_mode("regression")
xgb_param <-
xgb %>%
parameters() %>%
update(mtry = mtry(c(1, 20)), sample_size = sample_size(c(1, 500)))
wfset <- workflow_set(
preproc = list(xgb_recp = xbg_recip),
models = list(xgb_mod = xgb),
cross = FALSE
)
wkflow <- workflow() %>%
add_recipe(xbg_recip) %>%
add_model(xgb)
tuned_results <- wkflow %>%
tune_grid(
folds,
grid = 15,
param_info = xgb_param
)
tuned_results$.notes[[1]]
tuned_results$.notes[[1]][[1]]
xgb <- boost_tree(mtry = tune(),
trees = 1000,
min_n = tune(),
tree_depth = tune(),
learn_rate = tune()) %>%
set_engine("xgboost") %>%
set_mode("regression")
xgb_param <-
xgb %>%
parameters() %>%
update(mtry = mtry(c(1, 20)), sample_size = sample_size(c(1, 500)))
wfset <- workflow_set(
preproc = list(xgb_recp = xbg_recip),
models = list(xgb_mod = xgb),
cross = FALSE
)
wkflow <- workflow() %>%
add_recipe(xbg_recip) %>%
add_model(xgb)
tuned_results <- wkflow %>%
tune_grid(
folds,
grid = 15,
param_info = xgb_param
)
tuned_results$.notes[[1]]
tuned_results$.notes[[1]][[1]]
xbg_recip <- recipe(price ~ ., data = train) %>%
step_tokenize(name) %>%
step_stopwords(name) %>%
step_tokenfilter(name) %>%
step_tf(name) %>%
step_dummy(neighbourhood, neighbourhood_group) %>%
step_mutate(date_since_today = as.numeric(Sys.Date() - last_review)) %>%
step_mutate(distance_ctr = sqrt((tssq_lat - latitude)^2 + (tssq_lon - longitude)^2)) %>%
step_rm(all_nominal_predictors()) %>%
step_meanimpute(all_numeric_predictors())
linear_reg <- linear_reg() %>%
set_engine("lm")
xbg_recip <- recipe(price ~ ., data = train) %>%
step_tokenize(name) %>%
step_stopwords(name) %>%
step_tokenfilter(name) %>%
step_tf(name) %>%
step_dummy(neighbourhood, neighbourhood_group) %>%
step_mutate(date_since_today = as.numeric(Sys.Date() - last_review)) %>%
step_mutate(distance_ctr = sqrt((tssq_lat - latitude)^2 + (tssq_lon - longitude)^2)) %>%
step_rm(all_nominal_predictors()) %>%
step_impute_mean(all_numeric_predictors())
linear_reg <- linear_reg() %>%
set_engine("lm")
xgb <- boost_tree(mtry = tune(),
trees = 1000,
min_n = tune(),
tree_depth = tune(),
learn_rate = tune()) %>%
set_engine("xgboost") %>%
set_mode("regression")
xgb_param <-
xgb %>%
parameters() %>%
update(mtry = mtry(c(1, 20)), sample_size = sample_size(c(1, 500)))
wfset <- workflow_set(
preproc = list(xgb_recp = xbg_recip),
models = list(xgb_mod = xgb),
cross = FALSE
)
wkflow <- workflow() %>%
add_recipe(xbg_recip) %>%
add_model(xgb)
tuned_results <- wkflow %>%
tune_grid(
folds,
grid = 15,
param_info = xgb_param
)
tuned_results$.notes[[1]]
tuned_results$.notes[[1]][[1]]
xbg_recip %>% prep() %>% juice() %>% glimpse()
xbg_recip <- recipe(price ~ ., data = train) %>%
update_role(id, new_role = "id") %>%
step_tokenize(name) %>%
step_stopwords(name) %>%
step_tokenfilter(name) %>%
step_tf(name) %>%
step_dummy(neighbourhood, neighbourhood_group) %>%
step_mutate(date_since_today = as.numeric(Sys.Date() - last_review)) %>%
step_rm(date) %>%
step_mutate(distance_ctr = sqrt((tssq_lat - latitude)^2 + (tssq_lon - longitude)^2)) %>%
step_rm(all_nominal_predictors()) %>%
step_impute_mean(all_numeric_predictors())
linear_reg <- linear_reg() %>%
set_engine("lm")
xgb <- boost_tree(mtry = tune(),
trees = 1000,
min_n = tune(),
tree_depth = tune(),
learn_rate = tune()) %>%
set_engine("xgboost") %>%
set_mode("regression")
xgb_param <-
xgb %>%
parameters() %>%
update(mtry = mtry(c(1, 20)), sample_size = sample_size(c(1, 500)))
wfset <- workflow_set(
preproc = list(xgb_recp = xbg_recip),
models = list(xgb_mod = xgb),
cross = FALSE
)
wkflow <- workflow() %>%
add_recipe(xbg_recip) %>%
add_model(xgb)
tuned_results <- wkflow %>%
tune_grid(
folds,
grid = 15,
param_info = xgb_param
)
tuned_results$.notes[[1]]
tuned_results$.notes[[1]][[1]]
xbg_recip <- recipe(price ~ ., data = train) %>%
update_role(id, new_role = "id") %>%
step_tokenize(name) %>%
step_stopwords(name) %>%
step_tokenfilter(name) %>%
step_tf(name) %>%
step_dummy(neighbourhood, neighbourhood_group) %>%
step_mutate(date_since_today = as.numeric(Sys.Date() - last_review)) %>%
step_rm(last_review) %>%
step_mutate(distance_ctr = sqrt((tssq_lat - latitude)^2 + (tssq_lon - longitude)^2)) %>%
step_rm(all_nominal_predictors()) %>%
step_impute_mean(all_numeric_predictors())
linear_reg <- linear_reg() %>%
set_engine("lm")
xgb <- boost_tree(mtry = tune(),
trees = 1000,
min_n = tune(),
tree_depth = tune(),
learn_rate = tune()) %>%
set_engine("xgboost") %>%
set_mode("regression")
xgb_param <-
xgb %>%
parameters() %>%
update(mtry = mtry(c(1, 20)), sample_size = sample_size(c(1, 500)))
wfset <- workflow_set(
preproc = list(xgb_recp = xbg_recip),
models = list(xgb_mod = xgb),
cross = FALSE
)
wkflow <- workflow() %>%
add_recipe(xbg_recip) %>%
add_model(xgb)
tuned_results <- wkflow %>%
tune_grid(
folds,
grid = 15,
param_info = xgb_param
)
tuned_results %>% autoplot()
xgb_param <-
xgb %>%
parameters() %>%
update(mtry = mtry(c(1, 20))))
wfset <- workflow_set(
preproc = list(xgb_recp = xbg_recip),
models = list(xgb_mod = xgb),
cross = FALSE
)
wkflow <- workflow() %>%
add_recipe(xbg_recip) %>%
add_model(xgb)
tuned_results <- wkflow %>%
tune_grid(
folds,
grid = 15,
param_info = xgb_param
)
tuned_results %>%
autoplot()
xgb_param <-
xgb %>%
parameters() %>%
update(mtry = mtry(c(1, 20)))
wfset <- workflow_set(
preproc = list(xgb_recp = xbg_recip),
models = list(xgb_mod = xgb),
cross = FALSE
)
wkflow <- workflow() %>%
add_recipe(xbg_recip) %>%
add_model(xgb)
tuned_results <- wkflow %>%
tune_grid(
folds,
grid = 15,
param_info = xgb_param
)
tuned_results %>%
autoplot()
best_mod <- tuned_results %>%
select_best("rmse")
final_fit <- last_fit(best_mod, wkflow, split = splits)
final_fit <- last_fit(wkflow, best_mod,split = splits)
final_fit$.notes[[1]]
final_fit$.notes[[1]][[1]]
xgb <- boost_tree(mtry = tune(),
trees = 1000) %>%
set_engine("xgboost") %>%
set_mode("regression")
xgb_param <-
xgb %>%
parameters() %>%
update(mtry = mtry(c(1, 20)))
wfset <- workflow_set(
preproc = list(xgb_recp = xbg_recip),
models = list(xgb_mod = xgb),
cross = FALSE
)
wkflow <- workflow() %>%
add_recipe(xbg_recip) %>%
add_model(xgb)
tuned_results <- wkflow %>%
tune_grid(
folds,
grid = 15,
param_info = xgb_param
)
tuned_results
tuned_results %>% autoplot()
best_mod <- tuned_results %>%
select_best("rmse")
best_mod
xgb <- boost_tree(mtry = tune(),
trees = 1000,
min_n = tune(),
tree_depth = tune(),
learn_rate = tune()) %>%
set_engine("xgboost") %>%
set_mode("regression")
final_fit <- last_fit(wkflow, best_mod,split = splits)
?last_fit
wkflow <- workflow() %>%
add_recipe(xbg_recip) %>%
add_model(xgb)
final_fit <- last_fit(wkflow, best_mod, split = splits)
final_work <- wkflow %>%
finalize_workflow(best_mod)
final_fit <- last_fit(final_work, best_mod, split = splits)
hopreds <- predict(final_fit$.workflow[[1]], holdout)
holdout %>%
select(id) %>%
mutate(price = hopreds$.pred) %>%
write_csv(here::here("01_pred_2021_06_29.csv"))
xbg_recip <- recipe(price ~ ., data = train) %>%
update_role(id, new_role = "id") %>%
tep_tokenize(name) %>%
step_stopwords(name) %>%
step_tokenfilter(name) %>%
step_tf(name) %>%
step_dummy(neighbourhood_group) %>%
step_mutate(date_since_today = as.numeric(Sys.Date() - last_review)) %>%
step_rm(last_review) %>%
step_mutate(distance_ctr = sqrt((tssq_lat - latitude)^2 + (tssq_lon - longitude)^2)) %>%
step_rm(all_nominal_predictors()) %>%
step_impute_mean(all_numeric_predictors())
linear_reg <- linear_reg() %>%
set_engine("lm")
xgb <- boost_tree(mtry = tune(),
trees = 1000,
min_n = tune(),
tree_depth = tune(),
learn_rate = tune()) %>%
set_engine("xgboost") %>%
set_mode("regression")
xgb_param <-
xgb %>%
parameters() %>%
update(mtry = mtry(c(1, 20)))
wfset <- workflow_set(
preproc = list(xgb_recp = xbg_recip),
models = list(xgb_mod = xgb),
cross = FALSE
)
wkflow <- workflow() %>%
add_recipe(xbg_recip) %>%
add_model(xgb)
tuned_results <- wkflow %>%
tune_grid(
folds,
grid = 15,
param_info = xgb_param
)
tuned_results %>%
autoplot()
xgb <- boost_tree(mtry = tune(),
trees = 2000,
min_n = tune(),
tree_depth = tune(),
learn_rate = tune()) %>%
set_engine("xgboost") %>%
set_mode("regression")
xgb_param <-
xgb %>%
parameters() %>%
update(mtry = mtry(c(1, 20)))
wfset <- workflow_set(
preproc = list(xgb_recp = xbg_recip),
models = list(xgb_mod = xgb),
cross = FALSE
)
wkflow <- workflow() %>%
add_recipe(xbg_recip) %>%
add_model(xgb)
tuned_results <- wkflow %>%
tune_grid(
folds,
grid = 15,
param_info = xgb_param
)
tuned_results %>%
autoplot()
best_mod <- tuned_results %>%
select_best("rmse")
final_work <- wkflow %>%
finalize_workflow(best_mod)
final_fit <- last_fit(final_work, best_mod, split = splits)
hopreds <- predict(final_fit$.workflow[[1]], holdout)
holdout %>%
select(id) %>%
mutate(price = hopreds$.pred) %>%
write_csv(here::here("02_pred_2021_06_29.csv"))
ctrl_sa <- control_sim_anneal(verbose = TRUE, no_improve = 10L)
set.seed(1234)
xbg_sa <-
wkflow %>%
tune_sim_anneal(
resamples = folds,
metrics = metrics,
initial = tuned_results,
param_info = xgb_param,
iter = 10,
control = ctrl_sa)
xbg_sa %>%
autoplot()
xbg_recip <- recipe(price ~ ., data = train) %>%
update_role(id, new_role = "id") %>%
# step_tokenize(name) %>%
# step_stopwords(name) %>%
# step_tokenfilter(name) %>%
# step_tf(name) %>%
step_dummy(neighbourhood_group) %>%
step_mutate(date_since_today = as.numeric(Sys.Date() - last_review)) %>%
step_rm(last_review) %>%
step_mutate(distance_ctr = sqrt((tssq_lat - latitude)^2 + (tssq_lon - longitude)^2)) %>%
step_rm(all_nominal_predictors()) %>%
step_impute_mean(all_numeric_predictors())
linear_reg <- linear_reg() %>%
set_engine("lm")
xgb <- boost_tree(mtry = tune(),
trees = 2000,
min_n = tune(),
tree_depth = tune(),
learn_rate = tune()) %>%
set_engine("xgboost") %>%
set_mode("regression")
xgb_param <-
xgb %>%
parameters() %>%
update(mtry = mtry(c(1, 20)))
wfset <- workflow_set(
preproc = list(xgb_recp = xbg_recip),
models = list(xgb_mod = xgb),
cross = FALSE
)
wkflow <- workflow() %>%
add_recipe(xbg_recip) %>%
add_model(xgb)
tuned_results <- wkflow %>%
tune_grid(
folds,
grid = 15,
param_info = xgb_param
)
tuned_results %>%
autoplot()
best_mod <- tuned_results %>%
select_best("rmse")
final_work <- wkflow %>%
finalize_workflow(best_mod)
final_fit <- last_fit(final_work, best_mod, split = splits)
hopreds <- predict(final_fit$.workflow[[1]], holdout)
holdout %>%
select(id) %>%
mutate(price = hopreds$.pred) %>%
write_csv(here::here("04_pred_2021_06_29.csv"))
2 |>
2 |> \(x) x+1
2 |> + 3
2 |? \(x) x+1
2 |> \(x) x+1
2 |> (\(x) x+1)()
>|
\>
?|>
?`|>`
2 |> (\(x) x+1)()
2 |> (\(x) log(x))()
2 |> ((x) log(x))()
2 |> (\(x) log(x))()
2 |> (\(x) type(x)()
2 |> (\(x) type(x))()
2 |> (\(x) typeof(x))()
