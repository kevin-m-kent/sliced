step_tokenfilter(Title, Subtitle, Name) %>%
step_lda(Title, Subtitle, Name, num_topics = tune())
recp_2g <- recipe(TotalViews ~ ., data = train) %>%
update_role(Id, new_role = "Id") %>%
step_mutate(Title = tolower(Title), Subtitle = tolower(Subtitle), Name = tolower(Name)) %>%
step_tokenize(Title, Subtitle, Name, token = "ngrams", options = list(n = 2,
ngram_delim = " ")) %>%
step_stopwords(Title, Subtitle, Name) %>%
step_tokenfilter(Title, Subtitle, Name) %>%
step_lda(Title, Subtitle, Name, num_topics = tune())
randf <- rand_forest(mtry = tune(), min_n = tune(), trees = 1000) %>%
set_engine("ranger") %>%
set_mode("regression")
rf_param <-
randf %>%
parameters() %>%
update(mtry = mtry(c(1, 30)))
wfset <-  workflow_set(preproc = list(one_gram = recp_1g, two_gram = recp_2g),
models = list(randf = randf))
wfset <-
wfset %>%
option_add(param = rf_param, id = "one_gram_randf") %>%
option_add(param = rf_param, id = "two_gram_randf")
grid_ctrl <-
control_grid(
save_pred = TRUE,
parallel_over = "everything",
save_workflow = FALSE
)
grid_results <-
wfset %>%
workflow_map(
seed = 1503,
resamples = folds,
grid = 15,
control = grid_ctrl,
metrics = metrics,
verbose = TRUE
)
tunable.step_lda <- function(x, ...) {
tibble::tibble(
name = c("num_topics"),
call_info = list(list(pkg = NULL, fun = "num_topics", range = c(1L, 20L))),
source = "preproc",
component = "step_lda",
component_id = "main"
)
}
recp_1g <- recipe(TotalViews ~ ., data = train) %>%
update_role(Id, new_role = "Id") %>%
step_mutate(Title = tolower(Title), Subtitle = tolower(Subtitle), Name = tolower(Name)) %>%
step_tokenize(Title, Subtitle, Name, token = "ngrams", options = list(n = 1,
ngram_delim = " ")) %>%
step_stopwords(Title, Subtitle, Name) %>%
step_tokenfilter(Title, Subtitle, Name) %>%
step_lda(Title, Subtitle, Name, num_topics = tune())
recp_2g <- recipe(TotalViews ~ ., data = train) %>%
update_role(Id, new_role = "Id") %>%
step_mutate(Title = tolower(Title), Subtitle = tolower(Subtitle), Name = tolower(Name)) %>%
step_tokenize(Title, Subtitle, Name, token = "ngrams", options = list(n = 2,
ngram_delim = " ")) %>%
step_stopwords(Title, Subtitle, Name) %>%
step_tokenfilter(Title, Subtitle, Name) %>%
step_lda(Title, Subtitle, Name, num_topics = tune())
randf <- rand_forest(mtry = tune(), min_n = tune(), trees = 1000) %>%
set_engine("ranger") %>%
set_mode("regression")
rf_param <-
randf %>%
parameters() %>%
update(mtry = mtry(c(1, 30)))
wfset <-  workflow_set(preproc = list(one_gram = recp_1g, two_gram = recp_2g),
models = list(randf = randf))
wfset <-
wfset %>%
option_add(param = rf_param, id = "one_gram_randf") %>%
option_add(param = rf_param, id = "two_gram_randf")
grid_ctrl <-
control_grid(
save_pred = TRUE,
parallel_over = "everything",
save_workflow = FALSE
)
grid_results <-
wfset %>%
workflow_map(
seed = 1503,
resamples = folds,
grid = 15,
control = grid_ctrl,
metrics = metrics,
verbose = TRUE
)
num_topics <- function(range = c(1L, 20L), trans = NULL) {
new_quant_param(
type = "integer",
range = range,
inclusive = c(TRUE, TRUE),
trans = trans,
label = c(num_topics = "# LDA Topics"),
finalize = NULL
)
}
tunable.step_lda <- function(x, ...) {
tibble::tibble(
name = c("num_topics"),
call_info = list(list(pkg = NULL, fun = "num_topics", range = c(1L, 20L))),
source = "preproc",
component = "step_lda",
component_id = "main"
)
}
recp_1g <- recipe(TotalViews ~ ., data = train) %>%
update_role(Id, new_role = "Id") %>%
step_mutate(Title = tolower(Title), Subtitle = tolower(Subtitle), Name = tolower(Name)) %>%
step_tokenize(Title, Subtitle, Name, token = "ngrams", options = list(n = 1,
ngram_delim = " ")) %>%
step_stopwords(Title, Subtitle, Name) %>%
step_tokenfilter(Title, Subtitle, Name) %>%
step_lda(Title, Subtitle, Name, num_topics = tune())
recp_2g <- recipe(TotalViews ~ ., data = train) %>%
update_role(Id, new_role = "Id") %>%
step_mutate(Title = tolower(Title), Subtitle = tolower(Subtitle), Name = tolower(Name)) %>%
step_tokenize(Title, Subtitle, Name, token = "ngrams", options = list(n = 2,
ngram_delim = " ")) %>%
step_stopwords(Title, Subtitle, Name) %>%
step_tokenfilter(Title, Subtitle, Name) %>%
step_lda(Title, Subtitle, Name, num_topics = tune())
randf <- rand_forest(mtry = tune(), min_n = tune(), trees = 1000) %>%
set_engine("ranger") %>%
set_mode("regression")
rf_param <-
randf %>%
parameters() %>%
update(mtry = mtry(c(1, 30)))
wfset <-  workflow_set(preproc = list(one_gram = recp_1g, two_gram = recp_2g),
models = list(randf = randf))
wfset <-
wfset %>%
option_add(param = rf_param, id = "one_gram_randf") %>%
option_add(param = rf_param, id = "two_gram_randf")
grid_ctrl <-
control_grid(
save_pred = TRUE,
parallel_over = "everything",
save_workflow = FALSE
)
grid_results <-
wfset %>%
workflow_map(
seed = 1503,
resamples = folds,
grid = 15,
control = grid_ctrl,
metrics = metrics,
verbose = TRUE
)
wflow <- workflow() %>%
add_recipe(recp_2g) %>%
add_model(ranf)
randf <- rand_forest(mtry = tune(), min_n = tune(), trees = 1000) %>%
set_engine("ranger") %>%
set_mode("regression")
wflow <- workflow() %>%
add_recipe(recp_2g) %>%
add_model(ranf)
wflow <- workflow() %>%
add_recipe(recp_2g) %>%
add_model(randf)
rf_param <-
randf %>%
parameters() %>%
update(mtry = mtry(c(1, 30)))
?tune_grid
test_grid <- tune_grid(
wflow,
resamples = folds,
grid  = 10,
param_info = rf_param
)
test_grid$.notes[[1]]
test_grid$.notes[[1]][[1]]
wflow <- workflow() %>%
add_recipe(recp_2g) %>%
add_model(randf) %>%
parameters() %>%
update(mtry = mtry(c(1, 30)))
test_grid <- tune_grid(
wflow,
resamples = folds,
grid  = 10
)
wflow <- workflow() %>%
add_recipe(recp_2g) %>%
add_model(randf) %>%
parameters() %>%
update(mtry = mtry(c(1, 30)))
test_grid <- tune_grid(
wflow,
resamples = folds,
grid  = 10
)
wflow <- workflow() %>%
add_recipe(recp_2g) %>%
add_model(randf)
test_grid <- tune_grid(
wflow,
resamples = folds,
grid  = 10
)
rf_param <-
randf %>%
parameters() %>%
update(mtry = mtry(c(1, 30)))
wflow <- workflow() %>%
add_recipe(recp_2g) %>%
add_model(randf)
test_grid <- tune_grid(
wflow,
resamples = folds,
grid  = 10,
param_info = rf_param
)
test_grid$.notes[[1]]
test_grid$.notes[[1]][[1]]
devtools::install_github("tidymodels/tune")
# Loading Libraries -------------------------------------------------------
library(tidymodels)
library(usemodels)
library(tidyverse)
library(GGally)
library(skimr)
library(naniar)
library(plotly)
library(visdat)
library(finetune)
library(glue)
library(textrecipes)
source("step_isofor.R")
doParallel::registerDoParallel(cores = 6)
# Reading Data ---------------------------------------------------------------------
#https://www.kaggle.com/c/sliced-s00e04/overview
episode <- "s00e04"
raw_data <- read_csv(here::here("Raw_Data", glue("sliced-{episode}"),  glue("{episode}-sliced_data.csv")))
holdout <- read_csv(here::here("Raw_Data", glue("sliced-{episode}"),  glue("{episode}-holdout-data.csv")))
split <- initial_split(raw_data)
train <- training(split)
test <- testing(split)
folds <- validation_split(train)
metrics <- metric_set(rmse)
num_topics <- function(range = c(1L, 20L), trans = NULL) {
new_quant_param(
type = "integer",
range = range,
inclusive = c(TRUE, TRUE),
trans = trans,
label = c(num_topics = "# LDA Topics"),
finalize = NULL
)
}
tunable.step_lda <- function(x, ...) {
tibble::tibble(
name = c("num_topics"),
call_info = list(list(pkg = NULL, fun = "num_topics")),
source = "preproc",
component = "step_lda",
component_id = "main"
)
}
recp_1g <- recipe(TotalViews ~ ., data = train) %>%
update_role(Id, new_role = "Id") %>%
step_mutate(Title = tolower(Title), Subtitle = tolower(Subtitle), Name = tolower(Name)) %>%
step_tokenize(Title, Subtitle, Name, token = "ngrams", options = list(n = 1,
ngram_delim = " ")) %>%
step_stopwords(Title, Subtitle, Name) %>%
step_tokenfilter(Title, Subtitle, Name) %>%
step_lda(Title, Subtitle, Name, num_topics = tune())
recp_2g <- recipe(TotalViews ~ ., data = train) %>%
update_role(Id, new_role = "Id") %>%
step_mutate(Title = tolower(Title), Subtitle = tolower(Subtitle), Name = tolower(Name)) %>%
step_tokenize(Title, Subtitle, Name, token = "ngrams", options = list(n = 2,
ngram_delim = " ")) %>%
step_stopwords(Title, Subtitle, Name) %>%
step_tokenfilter(Title, Subtitle, Name) %>%
step_lda(Title, Subtitle, Name, num_topics = tune())
randf <- rand_forest(mtry = tune(), min_n = tune(), trees = 1000) %>%
set_engine("ranger") %>%
set_mode("regression")
rf_param <-
randf %>%
parameters() %>%
update(mtry = mtry(c(1, 30)))
wflow <- workflow() %>%
add_recipe(recp_2g) %>%
add_model(randf)
test_grid <- tune_grid(
wflow,
resamples = folds,
grid  = 10,
metrics = metrics,
param_info = rf_param
)
test_grid$.notes
test_grid$.notes[[1]]
test_grid$.notes[[1]][[1]]
cntrl <- control_grid(verbose = TRUE)
?tune_grid
test_grid <- tune_grid(
wflow,
resamples = folds,
grid  = crossing(mtry = seq(1, 10, by = 2), min_n = seq(1, 10, by = 2), num_topics = seq(1, 10, by =2)),
metrics = metrics,
param_info = rf_param,
control = cntrl
)
test_grid$.notes
test_grid$.notes[[1]]
test_grid$.notes[[1]][[1]]
sessionInfo()
devtools::install_github("tidymodels/finetune")
library(tidymodels)
library(usemodels)
library(tidyverse)
library(GGally)
library(skimr)
library(naniar)
library(plotly)
library(visdat)
library(finetune)
library(glue)
library(textrecipes)
source("step_isofor.R")
doParallel::registerDoParallel(cores = 6)
# Reading Data ---------------------------------------------------------------------
#https://www.kaggle.com/c/sliced-s00e04/overview
episode <- "s00e04"
raw_data <- read_csv(here::here("Raw_Data", glue("sliced-{episode}"),  glue("{episode}-sliced_data.csv")))
holdout <- read_csv(here::here("Raw_Data", glue("sliced-{episode}"),  glue("{episode}-holdout-data.csv")))
split <- initial_split(raw_data)
train <- training(split)
test <- testing(split)
folds <- validation_split(train)
metrics <- metric_set(rmse)
# Custom Tunable Methods --------------------------------------------------
num_topics <- function(range = c(1L, 20L), trans = NULL) {
new_quant_param(
type = "integer",
range = range,
inclusive = c(TRUE, TRUE),
trans = trans,
label = c(num_topics = "# LDA Topics"),
finalize = NULL
)
}
tunable.step_lda <- function(x, ...) {
tibble::tibble(
name = c("num_topics"),
call_info = list(list(pkg = NULL, fun = "num_topics")),
source = "preproc",
component = "step_lda",
component_id = "main"
)
}
# Model Setup -------------------------------------------------------------
recp_1g <- recipe(TotalViews ~ ., data = train) %>%
update_role(Id, new_role = "Id") %>%
step_mutate(Title = tolower(Title), Subtitle = tolower(Subtitle), Name = tolower(Name)) %>%
step_tokenize(Title, Subtitle, Name, token = "ngrams", options = list(n = 1,
ngram_delim = " ")) %>%
step_stopwords(Title, Subtitle, Name) %>%
step_tokenfilter(Title, Subtitle, Name) %>%
step_lda(Title, Subtitle, Name, num_topics = tune())
recp_2g <- recipe(TotalViews ~ ., data = train) %>%
update_role(Id, new_role = "Id") %>%
step_mutate(Title = tolower(Title), Subtitle = tolower(Subtitle), Name = tolower(Name)) %>%
step_tokenize(Title, Subtitle, Name, token = "ngrams", options = list(n = 2,
ngram_delim = " ")) %>%
step_stopwords(Title, Subtitle, Name) %>%
step_tokenfilter(Title, Subtitle, Name) %>%
step_lda(Title, Subtitle, Name, num_topics = tune())
randf <- rand_forest(mtry = tune(), min_n = tune(), trees = 1000) %>%
set_engine("ranger") %>%
set_mode("regression")
rf_param <-
randf %>%
parameters() %>%
update(mtry = mtry(c(1, 30)))
# Simple Workflow ---------------------------------------------------------
wflow <- workflow() %>%
add_recipe(recp_2g) %>%
add_model(randf)
cntrl <- control_grid(verbose = TRUE)
test_grid <- tune_grid(
wflow,
resamples = folds,
grid  = crossing(mtry = seq(1, 10, by = 2), min_n = seq(1, 10, by = 2), num_topics = seq(1, 10, by =2)),
metrics = metrics,
param_info = rf_param,
control = cntrl
)
test_grid$.notes
test_grid$.notes[[1]]
test_grid$.notes[[1]][[1]]
wfset <-  workflow_set(preproc = list(one_gram = recp_1g, two_gram = recp_2g),
models = list(randf = randf))
wfset <-
wfset %>%
option_add(param = rf_param, id = "one_gram_randf") %>%
option_add(param = rf_param, id = "two_gram_randf")
grid_ctrl <-
control_grid(
save_pred = TRUE,
parallel_over = "everything",
save_workflow = FALSE
)
grid_results <-
wfset %>%
workflow_map(
seed = 1503,
resamples = folds,
grid = 15,
control = grid_ctrl,
metrics = metrics,
verbose = TRUE
)
# Loading Libraries -------------------------------------------------------
library(tidymodels)
library(usemodels)
library(tidyverse)
library(GGally)
library(skimr)
library(naniar)
library(plotly)
library(visdat)
library(finetune)
library(glue)
library(textrecipes)
source("step_isofor.R")
doParallel::registerDoParallel(cores = 6)
# Reading Data ---------------------------------------------------------------------
#https://www.kaggle.com/c/sliced-s00e04/overview
episode <- "s00e04"
raw_data <- read_csv(here::here("Raw_Data", glue("sliced-{episode}"),  glue("{episode}-sliced_data.csv")))
holdout <- read_csv(here::here("Raw_Data", glue("sliced-{episode}"),  glue("{episode}-holdout-data.csv")))
split <- initial_split(raw_data)
train <- training(split)
test <- testing(split)
folds <- validation_split(train)
metrics <- metric_set(rmse)
new_quant_param(
type = "integer",
range = range,
inclusive = c(TRUE, TRUE),
trans = trans,
label = c(num_topics = "# LDA Topics"),
finalize = NULL
)
num_topics <- function(range = c(1L, 20L), trans = NULL) {
new_quant_param(
type = "integer",
range = range,
inclusive = c(TRUE, TRUE),
trans = trans,
label = c(num_topics = "# LDA Topics"),
finalize = NULL
)
}
tunable.step_lda <- function(x, ...) {
tibble::tibble(
name = c("num_topics"),
call_info = list(list(pkg = NULL, fun = "num_topics")),
source = "preproc",
component = "step_lda",
component_id = "main"
)
}
recp_1g <- recipe(TotalViews ~ ., data = train) %>%
update_role(Id, new_role = "Id") %>%
step_mutate(Title = tolower(Title), Subtitle = tolower(Subtitle), Name = tolower(Name)) %>%
step_tokenize(Title, Subtitle, Name, token = "ngrams", options = list(n = 1,
ngram_delim = " ")) %>%
step_stopwords(Title, Subtitle, Name) %>%
step_tokenfilter(Title, Subtitle, Name) %>%
step_lda(Title, Subtitle, Name, num_topics = tune())
recp_2g <- recipe(TotalViews ~ ., data = train) %>%
update_role(Id, new_role = "Id") %>%
step_mutate(Title = tolower(Title), Subtitle = tolower(Subtitle), Name = tolower(Name)) %>%
step_tokenize(Title, Subtitle, Name, token = "ngrams", options = list(n = 2,
ngram_delim = " ")) %>%
step_stopwords(Title, Subtitle, Name) %>%
step_tokenfilter(Title, Subtitle, Name) %>%
step_lda(Title, Subtitle, Name, num_topics = tune())
randf <- rand_forest(mtry = tune(), min_n = tune(), trees = 1000) %>%
set_engine("ranger") %>%
set_mode("regression")
rf_param <-
randf %>%
parameters() %>%
update(mtry = mtry(c(1, 30)))
wflow <- workflow() %>%
add_recipe(recp_2g) %>%
add_model(randf)
cntrl <- control_grid(verbose = TRUE)
test_grid <- tune_grid(
wflow,
resamples = folds,
grid  = crossing(mtry = seq(1, 10, by = 2), min_n = seq(1, 10, by = 2), num_topics = seq(1, 10, by =2)),
metrics = metrics,
param_info = rf_param,
control = cntrl
)
test_grid$.notes[[1]][[1]]
